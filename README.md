# Tema-3---Processos-e-Gerencia-de-Processador
Tema 3 - Processos e Gerencia de Processador
Tema 3 - Processos e Gerencia de Processador


Defini√ß√£o
Defini√ß√£o de processos e threads e da forma como esses elementos devem ser estruturados para a constru√ß√£o de sistemas eficientes.


PROP√ìSITO
Atualmente, at√© os mais simples dispositivos contam com a capacidade de multiprocessamento. Os sistemas operacionais, acompanhando o r√°pido desenvolvimento da tecnologia, fornecem mecanismos que possibilitam a constru√ß√£o de sistemas concorrentes que buscam tirar o m√°ximo proveito desta capacidade. Saber explorar esta possibilidade √© fundamental para a forma√ß√£o de profissionais habilitados a resolverem os desafios demandados por sistemas que buscam alto desempenho.

Prepara√ß√£o
Antes de iniciar o conte√∫do deste tema, √© desej√°vel ter acesso a um computador (ou m√°quina virtual) com Linux instalado. Para os exemplos deste tema, foi utilizado o Ubuntu Desktop 20.04 LTS.


Kali Linux √© uma distribui√ß√£o baseada em Debian, projetada principalmente para testes de seguran√ßa e auditorias de sistemas. Ele vem com centenas de ferramentas √∫teis para realizar an√°lise de vulnerabilidades, explora√ß√£o, an√°lise forense e muito mais. Por ser voltado para profissionais de seguran√ßa cibern√©tica e hackers √©ticos, o Kali Linux √© amplamente usado em ambientes de penetration testing e pesquisa de seguran√ßa.


M√≥dulo 1
Descrever os conceitos de processos

M√≥dulo 2
Compreender como ocorre a constru√ß√£o de programas concorrentes

M√≥dulo 3
Identificar o mecanismo de comunica√ß√£o entre processos

M√≥dulo 4
Comparar as diferentes formas de escalonamento


---------------


Introdu√ß√£o
Neste tema, estudaremos os conceitos de processos e como eles s√£o utilizados para tirar proveito da capacidade de multiprocessamento dos equipamentos atuais. Para isso, veremos a cria√ß√£o de subprocessos e como eles se comunicam. Estudaremos tamb√©m o funcionamento dos threads, que s√£o linhas de execu√ß√£o concorrentes dentro de um processo, fornecendo ao programador/desenvolvedor os mecanismos necess√°rios para permitir a concorr√™ncia dentro de um processo.

Por fim, destacaremos os cuidados que devemos ter ao desenvolver sistemas que acessam dados compartilhados e os mecanismos que permitem o desenvolvimento seguro de tais aplica√ß√µes.

M√ìDULO 1  - Descrever os conceitos de processos  

Conceitos

Antes de iniciar
Neste tema, voc√™ ver√° alguns exemplos de funcionamento de programas e comandos. Para o desenvolvimento dos exemplos, foi utilizado o Sistema Operacional Ubuntu Desktop 20.04 LTS, por√©m voc√™ pode utilizar o Linux de sua prefer√™ncia. O esperado √© que n√£o haja diferen√ßa de utiliza√ß√£o entre as v√°rias distribui√ß√µes Linux.


Os programas utilizados como exemplo foram desenvolvidos em Linguagem C, uma linguagem cl√°ssica para o desenvolvimento de sistemas operacionais. O objetivo dos exemplos √© permitir que voc√™ possa ver a utiliza√ß√£o pr√°tica dos conceitos estudados no tema 

instalador de compilador -  Para instalar o compilador de Linguagem C no Ubuntu, assim como em qualquer distribui√ß√£o Linux derivada do Debian, basta executar no shell os comandos:

sudo apt-get update
sudo apt-get install gcc
------------
compilando - Para compilar um programa chamado prog.c basta entrar no shell, no diret√≥rio onde se encontra o programa, e executar o comando:

  
gcc prog.c
-------------
compilando especificando a saida :   Para compilar um programa e escolher o nome do arquivo execut√°vel que ser√° gerado, utilize o par√¢metro -o. Por exemplo, para compilar o programa prog.c e gerar como sa√≠da um arquivo execut√°vel prog, utilize o comando:

gcc prog.c -o prog
---------------

executando programas - 

Para executar o programa prog que acabou de ser compilado, execute o comando:

  
./prog

---------------

Modelo de processo
Os primeiros sistemas permitiam a execu√ß√£o de apenas um programa de cada vez, que deveria ter o controle completo do sistema e acesso a todos os seus recursos. Os sistemas atuais permitem que diversos programas sejam carregados na mem√≥ria e executados simultaneamente.

Essa evolu√ß√£o tornou necess√°rio um controle maior na divis√£o de tarefas dos v√°rios programas, resultando na no√ß√£o de processo.

Em um sistema multiprogram√°vel, a unidade central de processamento (UCP) alterna entre processos, dedicando um pouco de seu tempo a cada um, dando a ilus√£o de paralelismo. Este esquema costuma ser chamado de pseudoparalelismo.

Neste modelo, todo software executado no computador √© organizado em processos sequenciais, tamb√©m chamado de processos. O modelo de processos foi desenvolvido para tornar o paralelismo mais f√°cil de tratar.

Um processo √© um programa em execu√ß√£o, incluindo os valores atuais dos registradores e vari√°veis, assim como seu espa√ßo de endere√ßamento. Um programa por si s√≥ n√£o √© um processo, mas uma entidade passiva. Um processo √© uma entidade ativa, com um contador de instru√ß√µes e um conjunto de registradores a ele associado.

Aten√ß√£o
Embora dois processos possam estar associados a um mesmo programa, s√£o duas sequ√™ncias de execu√ß√£o distintas.

Conceitualmente, cada processo tem sua pr√≥pria UCP. Com a UCP alternando entre os processos, a velocidade com que um processo executa n√£o ser√° uniforme.


Exemplo de sistema de tempo compartilhado com 4 processos concorrentes.
Na figura anterior, vemos um exemplo de um sistema no qual s√£o executados os processos A, B, C e D. O processo A √© executado at√© o instante t1, quando para, e o processo B √© colocado em execu√ß√£o at√© o instante t2. Os processos alternam suas execu√ß√µes at√© que, no instante t4, o processo D para de executar e o processo A retoma sua execu√ß√£o.

Como os processos alternam suas execu√ß√µes de forma muito r√°pida, o usu√°rio tem a ilus√£o de que os processos est√£o realmente sendo executados ao mesmo tempo.

Cria√ß√£o e encerramento de processos
Sistemas operacionais precisam criar processos durante sua opera√ß√£o.

Quatro eventos principais fazem com que processos sejam criados:

Inicializa√ß√£o do sistema.

Execu√ß√£o de uma chamada de sistema de cria√ß√£o de processo por um processo em execu√ß√£o.

Solicita√ß√£o de um usu√°rio para criar um processo.

In√≠cio de uma tarefa em lote.

Quando um sistema operacional √© inicializado, uma s√©rie de processos s√£o criados. Alguns s√£o processos de primeiro plano (interagem com usu√°rios), enquanto outros operam no segundo plano (background) e n√£o est√£o associados a usu√°rios em particular. Processos que ficam em segundo plano para lidar com algumas atividades, como e-mail, p√°ginas da web, not√≠cias, impress√£o, s√£o chamados de daemons.

Al√©m dos processos criados durante a inicializa√ß√£o do sistema, outros tamb√©m podem ser criados. Muitas vezes, um processo em execu√ß√£o emitir√° chamadas de sistema para criar um ou mais processos para ajud√°-lo em seu trabalho. Criar processos novos √© particularmente √∫til quando o trabalho a ser feito pode ser facilmente formulado em termos de v√°rios processos relacionados. Em um multiprocessador, por exemplo, cada processo pode ser executado em uma UCP, fazendo com que a tarefa seja realizada mais rapidamente.

Em sistemas interativos, os usu√°rios podem come√ßar um programa digitando um comando ou clicando duas vezes sobre um √≠cone. Cada uma dessas a√ß√µes inicia um novo processo e executa o programa selecionado.

Tarefas em lote costumam ser executadas em grandes sistemas. As tarefas s√£o submetidas ao sistema e, quando o sistema operacional tem os recursos necess√°rios para executar outra tarefa, cria um processo e executa a pr√≥xima tarefa a partir da fila de entrada.

Aten√ß√£o
Em todos esses casos, um novo processo √© criado por outro j√° existente, executando uma chamada de sistema de cria√ß√£o de processo. O que esse processo faz √© executar uma chamada de sistema para criar o processo.

No Linux, a chamada de sistema mais comum para a cria√ß√£o de processos √© a fork(). Essa chamada cria um processo id√™ntico ao processo que a chamou. Ap√≥s a fork(), os dois processos, o pai e o filho, t√™m a mesma imagem de mem√≥ria, as mesmas vari√°veis de ambiente e os mesmos arquivos abertos.

O c√≥digo a seguir, em Linguagem C, exemplifica a cria√ß√£o de um novo processo com a chamada de sistema fork().

  
#include <stdio.h>
#include <unistd.h>
#include <sys/wait.h>

int main() {
int resultado, pid, ppid;
resultado = fork();
if (resultado < 0)
printf("Algo deu errado!!!\n");
pid = getpid();
if (resultado == 0) {
ppid = getppid();
printf("Eu sou o processo filho, meu PID √© %d e meu pai tem PID=%d.\n", pid, ppid);
}
if (resultado > 0) {
printf("Eu sou o processo pai, meu PID √© %d e meu filho tem PID=%d.\n", pid, resultado);
waitpid(resultado, NULL, 0);
}
}
Quando fork() √© executada, o resultado do processamento √© armazenado na vari√°vel ‚Äúresultado‚Äù. O processo pai (que fez a chamada) receber√° na vari√°vel ‚Äúresultado‚Äù o PID do processo filho, enquanto o processo filho receber√° na vari√°vel ‚Äúresultado‚Äù o valor 0. Assim, para saber quem √© o processo pai e quem √© o processo filho, √© necess√°rio verificar o valor em ‚Äúresultado‚Äù.

De in√≠cio, verifica-se a ocorr√™ncia de algum erro na cria√ß√£o do processo filho. Caso tenha ocorrido um erro, ‚Äúresultado‚Äù receber√° um valor negativo.

A seguir, o comando ‚Äúpid = getpid();‚Äù obt√©m o PID do processo corrente.

Ent√£o, o processo verifica o valor de ‚Äúresultado‚Äù. Se for zero, √© o processo filho que est√° executando e, nesse, caso o processo executa ‚Äúppid = getppid();‚Äù para obter o PID do processo pai. Se o valor de ‚Äúresultado‚Äù for maior que zero, significa que quem est√° executando √© o processo pai. Ambos (pai e filho) mostram na tela os respectivos PID.

Por fim, o processo pai executa a chamada de sistema ‚Äúwaitpid(resultado, NULL, 0);‚Äù para, antes de terminar, aguardar o t√©rmino da execu√ß√£o do filho.

Quando o fork() √© utilizado para a cria√ß√£o de um processo que executar√° o c√≥digo de outro programa, a chamada de sistema execve() deve ser utilizada para que o processo filho mude sua imagem de mem√≥ria e execute o novo programa.

O c√≥digo a seguir ilustra a utiliza√ß√£o de execve(). Nele, o processo pai cria tr√™s processos filhos em sequ√™ncia. O primeiro coloca em execu√ß√£o uma calculadora, o segundo, o editor de textos gedit, e o terceiro, o utilit√°rio xeyes.

  
#include <stdio.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char **argv, char* envp[]) {
int pid, i;

for (i=1; i<=3; i++) {
pid = fork();
if (pid < 0) {
printf("Algo deu errado!!!\n");
return 0;
}
if (pid == 0) { // Processo filho
if (i == 1)
execve("/usr/bin/xcalc", argv, envp);
if (i == 2)
execve("/usr/bin/gedit", argv, envp);
if (i == 3)
execve("/usr/bin/xeyes", argv, envp);
}
else // Processo pai
waitpid(pid, NULL, 0)
}
}
Ap√≥s ter executado sua tarefa, o novo processo terminar√° devido a uma das seguintes condi√ß√µes:

Clique nas setas para ver o conte√∫do.
Sa√≠da normal (volunt√°ria)

A maioria dos processos termina por terem realizado o seu trabalho. Quando isto ocorre, o processo executa uma chamada para dizer ao sistema operacional que ele terminou e para que o sistema possa tomar as provid√™ncias necess√°rias ao seu encerramento.

Erro fatal (involunt√°rio)

O processo tamb√©m pode terminar quando descobre um erro fatal. Ele pode solicitar ao usu√°rio uma nova entrada de dados ou simplesmente encerrar sua execu√ß√£o de maneira similar √† sa√≠da normal.

Sa√≠da por erro (volunt√°ria)

Outra raz√£o para o t√©rmino √© um erro causado pelo processo, muitas vezes decorrente de um erro de programa. Exemplos incluem executar uma instru√ß√£o ilegal, referenciar uma mem√≥ria n√£o existente ou dividir por zero.

Morto por outro processo (involunt√°rio)

A quarta raz√£o pela qual um processo pode ser finalizado √© a execu√ß√£o de uma chamada de sistema dizendo ao sistema operacional para matar outro processo. Para um processo matar outro, √© necess√°rio autoriza√ß√£o.

Em alguns sistemas, quando um processo √© finalizado, todos os processos que ele criou s√£o finalizados tamb√©m. Nem o Linux nem o Windows funcionam desta forma.

Hierarquia de processos
Em alguns sistemas, quando um processo cria outro, o processo pai e o processo filho continuam associados. O processo filho pode criar mais processos, formando uma hierarquia de processos. No Linux, um processo e todos os seus filhos e demais descendentes formam um grupo de processos.

No Linux, um processo especial chamado systemd (ou init, dependendo da vers√£o) est√° presente na imagem de inicializa√ß√£o do sistema. √â o primeiro processo a ser executado e √© respons√°vel por iniciar a execu√ß√£o dos demais processos do sistema operacional. Cada um desses processos pode iniciar mais processos. Desse modo, todos os processos no Linux pertencem a uma √∫nica √°rvore, com o systemd (ou init) em sua raiz.


A imagem a seguir exemplifica a √°rvore de processos em um sistema Linux por meio da execu√ß√£o do comando ‚Äúpstree‚Äù.

  
systemd-+-ModemManager---2*[{ModemManager}]
|-NetworkManager---2*[{NetworkManager}]
|-VBoxService---8*[{VBoxService}]
|-accounts-daemon---2*[{accounts-daemon}]
|-acpid
|-avahi-daemon---avahi-daemon
|-colord---2*[{colord}]
|-cron
|-cups-browsed---2*[{cups-browsed}]
|-cupsd
|-dbus-daemon
|-gdm3-+-gdm-session-wor-+-gdm-wayland-ses-+-gnome-session-b---3*[{gnome-session-b}]
| | | `-2*[{gdm-wayland-ses}]
| | `-2*[{gdm-session-wor}]
| `-2*[{gdm3}]
|-2*[kerneloops]
|-login---bash---pstree
|-networkd-dispat
|-polkitd---2*[{polkitd}]
|-rsyslogd---3*[{rsyslogd}]
|-rtkit-daemon---2*[{rtkit-daemon}]
|-snapd---8*[{snapd}]
|-switcheroo-cont---2*[{switcheroo-cont}]
|-systemd---(sd-pam)
|-systemd-+-(sd-pam)
| |-at-spi-bus-laun-+-dbus-daemon
| | `-3*[{at-spi-bus-laun}]
| |-at-spi2-registr---2*[{at-spi2-registr}]
| |-dbus-daemon
| |-gjs---4*[{gjs}]
| |-gnome-keyring-d---3*[{gnome-keyring-d}]
| |-gnome-session-b---3*[{gnome-session-b}]
| |-gnome-session-c---{gnome-session-c}
| |-gnome-shell-+-Xwayland
| | |-ibus-daemon-+-ibus-engine-sim---2*[{ibus-engine-sim}]
| | | |-ibus-memconf---2*[{ibus-memconf}]
| | | `-2*[{ibus-daemon}]
| | `-6*[{gnome-shell}]
| |-goa-daemon---3*[{goa-daemon}]
| |-goa-identity-se---2*[{goa-identity-se}]
| |-gsd-a11y-settin---3*[{gsd-a11y-settin}]
| |-gsd-color---3*[{gsd-color}]
| |-gsd-keyboard---3*[{gsd-keyboard}]
| |-gsd-media-keys---3*[{gsd-media-keys}]
| |-gsd-power---3*[{gsd-power}]
| |-gsd-print-notif---2*[{gsd-print-notif}]
| |-gsd-printer---2*[{gsd-printer}]
| |-gsd-rfkill---2*[{gsd-rfkill}]
| |-gsd-smartcard---4*[{gsd-smartcard}]
| |-gsd-sound---3*[{gsd-sound}]
| |-gsd-usb-protect---3*[{gsd-usb-protect}]
| |-gsd-wacom---3*[{gsd-wacom}]
| |-gsd-wwan---3*[{gsd-wwan}]
| |-gsd-xsettings---3*[{gsd-xsettings}]
| |-gvfs-afc-volume---3*[{gvfs-afc-volume}]
| |-gvfs-goa-volume---2*[{gvfs-goa-volume}]
| |-gvfs-gphoto2-vo---2*[{gvfs-gphoto2-vo}]
| |-gvfs-mtp-volume---2*[{gvfs-mtp-volume}]
| |-gvfs-udisks2-vo---3*[{gvfs-udisks2-vo}]
| |-gvfsd---2*[{gvfsd}]
| |-gvfsd-fuse---5*[{gvfsd-fuse}]
| |-ibus-portal---2*[{ibus-portal}]
| |-ibus-x11---2*[{ibus-x11}]
| |-pulseaudio---3*[{pulseaudio}]
| |-tracker-miner-f---4*[{tracker-miner-f}]
| `-xdg-permission----2*[{xdg-permission-}]
|-systemd-journal
|-systemd-logind
|-systemd-resolve
|-systemd-timesyn---{systemd-timesyn}
|-systemd-udevd
|-udisksd---4*[{udisksd}]
|-unattended-upgr---{unattended-upgr}
|-upowerd---2*[{upowerd}]
|-whoopsie---2*[{whoopsie}]
`-wpa_supplicant
Estados de processos
Eventualmente, um processo que est√° em execu√ß√£o necessita parar momentaneamente sua execu√ß√£o por estar aguardando uma informa√ß√£o ainda n√£o dispon√≠vel ou porque j√° foi executado por muito tempo e precisa liberar a UCP para outro processo.

Um processo pode transitar por diferentes estados, que dependem do sistema operacional. De forma geral, podemos dizer que um processo pode estar nos estados novo, executando, pronto, bloqueado ou terminado.


Quando um processo √© criado, ele se inicia no estado novo. O processo j√° existe, mas ainda precisam ser tomadas algumas provid√™ncias pelo sistema operacional para que o processo possa iniciar sua execu√ß√£o. Quando tudo est√° pronto, o processo faz a transi√ß√£o 1 e muda para o estado pronto.

O processo re√∫ne todas as condi√ß√µes para ser executado quando est√° no estado pronto, faltando apenas que o processador fique dispon√≠vel para sua execu√ß√£o. Quando um processador fica dispon√≠vel e o processo √© selecionado para execu√ß√£o, ele faz a transi√ß√£o 2 e vai para o estado executando.

No estado executando, o processo tem suas instru√ß√µes executadas pelo processador e tr√™s coisas podem acontecer:

Escolha uma das Etapas a seguir.

1. A primeira delas √© o processo ser executado por muito tempo. Ent√£o, o sistema operacional interrompe momentaneamente a execu√ß√£o do processo para colocar outro em seu lugar, ocorrendo a transi√ß√£o 3, que leva o processo de volta ao estado pronto, no qual aguardar√° nova oportunidade de execu√ß√£o.

2. Pode ocorrer ainda de o processo solicitar uma opera√ß√£o de entrada e sa√≠da e ter de aguardar a conclus√£o da opera√ß√£o, que costuma ser demorada quando comparada √† capacidade de processamento do processador de um computador. Nesse caso, ocorre a transi√ß√£o 4, e o processo vai para o estado bloqueado.

3. Por √∫ltimo, o processo pode encerrar sua execu√ß√£o, realizando a transi√ß√£o 6 e indo para o estado terminado.


O processo que vai para o estado bloqueado permanece nele at√© que seja conclu√≠da a opera√ß√£o que aguardava. Quando isso ocorre, o processo passa pela transi√ß√£o 5 e vai para o estado pronto at√© ser novamente selecionado para execu√ß√£o.

Aten√ß√£o
O estado terminado √© para os processos que n√£o ser√£o mais executados. Quando est√° neste estado, o sistema operacional deve providenciar a desaloca√ß√£o dos recursos que ainda estejam alocados ao processo. Somente ap√≥s a desaloca√ß√£o de todos os recursos, o processo deixa de existir no sistema.

Para implementar o modelo de processos, o Linux mant√©m uma tabela de processos, com uma entrada por processo. Esta entrada √© chamada de Bloco de Controle de Processo ‚Äì BCP (Process Control Block ‚Äì PCB) e cont√©m todas as informa√ß√µes do processo. Algumas entradas do BCP s√£o:

Estado do processo

Prioridade do processo

N√∫mero do processo

Registradores da UCP

Informa√ß√µes relativas ao gerenciamento de mem√≥ria

Informa√ß√µes de contabilidade

Informa√ß√µes sobre opera√ß√µes de E/S

Essa vis√£o d√° origem ao seguinte modelo:


O n√≠vel mais baixo do sistema operacional √© o escalonador (tamb√©m conhecido como agendador). Ele cuida do gerenciamento de interrup√ß√µes e dos detalhes de como iniciar e parar processos. Tamb√©m costuma ser muito pequeno.

Um processo passa pelas v√°rias filas de sele√ß√£o durante sua execu√ß√£o. Cabe ao escalonador selecionar processos destas filas e decidir qual ser√° o pr√≥ximo a ser executado.


O escalonador √© chamado com muita frequ√™ncia. Um processo pode ser executado por apenas alguns milissegundos (ms) e ter de esperar por ter feito uma requisi√ß√£o de E/S. O escalonador costuma ser chamado pelo menos uma vez a cada 100ms para realizar a troca de processos. Devido ao pequeno intervalo de tempo entre as chamadas ao escalonador, sua execu√ß√£o deve ser bastante r√°pida, para que n√£o se gaste muito tempo de UCP com trabalho de ger√™ncia.

Mudan√ßa de contexto
Para transferir o controle da UCP de um processo a outro, √© necess√°rio guardar o estado do processo em execu√ß√£o e carregar o estado do processo a entrar em execu√ß√£o. Esta tarefa √© conhecida como mudan√ßa de contexto (ou troca de contexto).

O tempo gasto na mudan√ßa de contexto varia, dependendo de fatores como velocidade da mem√≥ria, quantidade de registradores e exist√™ncia de instru√ß√µes especiais. Este tempo costuma variar de 1 a 1000 microssegundos.

O contexto de um processo pode ser dividido em tr√™s elementos b√°sicos:

Clique nas barras para ver as informa√ß√µes.
Contexto de hardware - O contexto de hardware constitui-se basicamente do conte√∫do dos registradores. No momento em que o processo perde a UCP, o sistema salva suas informa√ß√µes. Ele √© fundamental para a implementa√ß√£o dos sistemas multiprogram√°veis.
-----------
Contexto de software - O contexto de software especifica caracter√≠sticas do processo que influenciar√£o na execu√ß√£o de um programa. Ele define basicamente tr√™s grupos de informa√ß√µes sobre um processo: identifica√ß√£o, quotas e privil√©gios. A identifica√ß√£o define o processo para o sistema de forma √∫nica, atrav√©s de seu PID, UID e GID. Quotas s√£o os limites de cada recurso que o sistema operacional pode alocar, como n√∫mero de arquivos abertos, quantidade de mem√≥ria, quantidade de subprocessos que podem ser criados etc. Privil√©gio √© o que o processo pode ou n√£o fazer em rela√ß√£o ao sistema e outros processos.
------------
Espa√ßo de endere√ßamento
O espa√ßo de endere√ßamento √© a √°rea de mem√≥ria do processo em que o programa ser√° executado e a √°rea de mem√≥ria onde os dados do processo ser√£o armazenados. Cada processo possui seu pr√≥prio espa√ßo de endere√ßamento, que deve ser protegido dos demais.
------------
Processos no Linux

Os processos no Linux comportam-se como processos sequenciais tradicionais. √â um sistema operacional multiusu√°rio/multitarefa, que permite a execu√ß√£o simult√¢nea de diversos processos, que podem pertencer a diferentes usu√°rios. Mesmo que haja apenas um usu√°rio logado no sistema, √© comum a exist√™ncia de diversos daemons em execu√ß√£o.
----------
Um exemplo √© o daemon de impress√£o, respons√°vel por fazer a aloca√ß√£o da impressora e controlar o envio de trabalhos de impress√£o. √â uma parte importante do sistema, pois permite o compartilhamento da impressora por diversos processos, possivelmente pertencentes a diferentes usu√°rios.

-----------

A forma usual para cria√ß√£o de processos no Linux ocorre por meio da chamada de sistema fork(), conforme voc√™ j√° estudou neste tema.

O processo filho recebe uma c√≥pia exata do espa√ßo de endere√ßamento do processo pai. Todos os valores de vari√°veis e demais objetos em mem√≥ria ser√£o id√™nticos, por√©m altera√ß√µes realizadas por um dos processos em qualquer conte√∫do de mem√≥ria n√£o afetar√£o o outro.

Arquivos que foram abertos antes da chamada fork() permanecem abertos para o processo pai e para o processo filho. As altera√ß√µes realizadas por qualquer um destes processos se tornam imediatamente dispon√≠veis para o outro. Processos s√£o identificados por um n√∫mero inteiro conhecido como PID (identifica√ß√£o do processo).


-------------

Linux e suas respectivas descri√ß√µes para o gerenciamento de processos:

Chamadas de Sistema do Linux para Gerenciamento de Processos
Chamada de Sistema	Descri√ß√£o
fork()	Cria um processo filho id√™ntico ao processo pai. Para o processo pai, retorna o PID do processo filho; para o processo filho, retorna o valor 0.
waitpid()	Aguarda at√© que o processo filho especificado como par√¢metro termine sua execu√ß√£o.
execve()	Substitui a imagem de execu√ß√£o do processo atual, fazendo com que ele execute o programa passado como par√¢metro.
exit()	Termina a execu√ß√£o do processo atual e retorna um status ao processo pai.

Se quiser, posso montar exemplos de c√≥digo em C demonstrando o uso dessas chamadas. Deseja isso?


Perfeito! Abaixo est√° um exemplo simples em C que demonstra o uso das chamadas de sistema fork(), execve(), waitpid() e exit() para o gerenciamento de processos no Linux:

üß† Objetivo do exemplo:
Criar um processo filho com fork().

O filho executa um programa externo com execve().

O pai aguarda o t√©rmino do filho com waitpid().

O filho finaliza com exit().


#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/wait.h>

int main() {
    pid_t pid;
    int status;

    pid = fork();  // Cria o processo filho

    if (pid < 0) {
        // Erro ao criar processo
        perror("fork falhou");
        exit(1);
    } else if (pid == 0) {
        // C√≥digo executado pelo processo filho
        printf("Filho: Meu PID √© %d\n", getpid());

        char *args[] = {"/bin/ls", "-l", NULL};  // Comando a ser executado
        execve("/bin/ls", args, NULL);  // Executa o comando 'ls -l'

        // Se execve falhar
        perror("execve falhou");
        exit(1);
    } else {
        // C√≥digo executado pelo processo pai
        printf("Pai: Criei o processo filho com PID %d\n", pid);
        waitpid(pid, &status, 0);  // Espera o filho terminar

        if (WIFEXITED(status)) {
            printf("Pai: Filho terminou com status %d\n", WEXITSTATUS(status));
        } else {
            printf("Pai: Filho terminou de forma anormal\n");
        }
    }

    return 0;
}
üîç Explica√ß√£o r√°pida:
fork() divide o processo atual em pai e filho.

O filho usa execve() para rodar o comando ls -l.

O pai aguarda com waitpid() e imprime o status de sa√≠da do filho.

O filho usa exit() implicitamente ao terminar.
-----------------------

Uma das formas de cria√ß√£o de subprocessos no Linux ocorre por meio da chamada de sistema fork(). Assinale a alternativa verdadeira em rela√ß√£o √† chamada de sistema fork():
A) Cria um subprocesso que √© uma c√≥pia do processo pai, compartilhando o espa√ßo de endere√ßamento do processo pai.
B) Cria um subprocesso que √© uma c√≥pia do processo pai, mas que possui seu pr√≥prio espa√ßo de endere√ßamento.
C) Cria um subprocesso que executa o c√≥digo de um programa passado como par√¢metro.
D) Cria um subprocesso com a mesma identifica√ß√£o (PID) do processo pai.

Coment√°rio:
‚úÖ Parab√©ns! A alternativa "B" est√° correta.
A chamada de sistema fork() cria um subprocesso que √© c√≥pia exata do processo pai, mas que compartilha com ele apenas os arquivos abertos. Portanto, n√£o h√° compartilhamento do espa√ßo de endere√ßamento com o processo pai.
Para executar o c√≥digo de outro programa, √© necess√°rio utilizar a chamada de sistema execve() ap√≥s a chamada de sistema fork().

2. √â comum um processo transitar por v√°rios estados durante sua vida em um sistema operacional. Sobre os estados de um processo, √© correto afirmar que:
A) Para que um processo mude de estado, √© necess√°ria a ocorr√™ncia de uma mudan√ßa de contexto.
B) Processos no estado pronto est√£o utilizando a UCP.
C) Processos no estado terminado n√£o existem mais no sistema operacional.
D) Processos que saem do estado bloqueado devem ir para o estado pronto antes de entrarem em execu√ß√£o.

Coment√°rio:
‚úÖ A alternativa "D" est√° correta.
Quando um processo est√° bloqueado (esperando algum evento externo, como a conclus√£o de uma opera√ß√£o de E/S), ele n√£o pode voltar diretamente √† execu√ß√£o. Primeiro, ele deve passar para o estado pronto, onde aguardar√° sua vez de ser escalonado para a UCP.

----------------

M√ìDULO 2 - Compreender como ocorre a constru√ß√£o de programas concorrentes

SUBPROCESSO
Quando um processo (processo pai) cria um outro processo, ele √© conhecido como subprocesso ou processo filho. O subprocesso, por sua vez, pode criar outros subprocessos.

A utiliza√ß√£o de subprocessos permite dividir uma aplica√ß√£o em partes que podem trabalhar de forma concorrente. Imagine, por exemplo:

Exemplo - Um servidor web que aceite requisi√ß√µes de clientes da internet e coloque as requisi√ß√µes em uma fila. Uma forma simples de implementar este servidor seria criar um processo que pegue a primeira requisi√ß√£o da fila, processe a requisi√ß√£o e devolva o resultado do processamento ao cliente que a solicitou. Ap√≥s isso, ele pegaria a pr√≥xima requisi√ß√£o e faria o mesmo trabalho.


O problema com essa solu√ß√£o √© que ela n√£o aproveita a capacidade de multiprocessamento dos sistemas atuais. Como existe apenas um processo em execu√ß√£o, somente um dos processadores do sistema √© utilizado para atendimento das requisi√ß√µes. Al√©m disso, se houver v√°rias requisi√ß√µes complexas e demoradas e uma requisi√ß√£o simples, como uma pequena p√°gina HTML, entrar no final da fila, esta requisi√ß√£o mais simples, que poderia ser respondida rapidamente, ser√° atendida somente depois que todas as demais forem processadas.

A utiliza√ß√£o de subprocessos resolve bem estes problemas. Se o servidor, no lugar de responder sequencialmente a cada requisi√ß√£o, criar um subprocesso para cada uma delas, tirar√° proveito da capacidade de multiprocessamento do sistema. Como cada requisi√ß√£o ser√° tratada por um processo diferente, as requisi√ß√µes ser√£o espalhadas pelos processadores do sistema, aproveitando sua capacidade de multiprocessamento. Al√©m disso, como as requisi√ß√µes ser√£o tratadas por diferentes processos, elas ser√£o executadas concorrentemente.

Dessa forma, uma requisi√ß√£o simples, como a solicita√ß√£o de uma p√°gina HTML, poder√° ser iniciada e respondida rapidamente, ainda que existam outras requisi√ß√µes complexas solicitadas anteriormente e que elas ainda estejam sendo processadas.

O trecho de c√≥digo abaixo em Linguagem C exemplifica a parte de um servidor web simples que cria subprocessos para atendimento das requisi√ß√µes:

  
while (1) { // Loop infinito
req = pega_proxima_requisicao();
pid = fork();
if (pid == 0) { // Proceso filho
processa_requisicao(req);
exit(0);
}
}


Entenda o significado de cada um deles:

‚Äúpega_proxima_requisicao()‚Äù
Neste c√≥digo, a rotina ‚Äúpega_proxima_requisicao()‚Äù √© respons√°vel por verificar se existe alguma requisi√ß√£o enfileirada para atendimento. Se n√£o houver, o processo pai fica bloqueado at√© que chegue uma nova requisi√ß√£o, sem impactar no desempenho do sistema. Enquanto isso, seus processos filhos continuam atendendo √†s requisi√ß√µes em andamento.

‚Äúprocessa_requisicao()‚Äù
A rotina ‚Äúprocessa_requisicao()‚Äù √© executada somente pelo processo filho, uma vez que o comando if anterior faz essa verifica√ß√£o. Essa rotina fica encarregada do atendimento √† requisi√ß√£o que foi enviada ao servidor web. Depois do processamento, a chamada de sistema ‚Äúexit(0)‚Äù encerra o processo filho.

‚Äúwhile (1) {‚Ä¶}‚Äù
Todo o c√≥digo fica contido em um loop infinito ‚Äúwhile (1) {‚Ä¶}‚Äù. Esse loop repetidamente pega a pr√≥xima requisi√ß√£o da fila, cria um processo filho para atendimento da requisi√ß√£o e retorna a aguardar uma nova requisi√ß√£o, enquanto o processo filho faz o processamento da requisi√ß√£o que acabou de chegar.


Threads
Na tentativa de diminuir o tempo gasto na cria√ß√£o/elimina√ß√£o de processos, bem como economizar recursos do sistema, foi introduzido o conceito de thread. Em um ambiente com m√∫ltiplos threads, n√£o √© necess√°rio haver v√°rios processos para implementar aplica√ß√µes concorrentes.



Threads compartilham o processador da mesma maneira que um processo. Cada thread possui seu pr√≥prio conjunto de registradores (contexto de hardware), por√©m compartilha o mesmo espa√ßo de endere√ßamento com os demais threads do processo. No momento em que um thread perde a utiliza√ß√£o do processador, o sistema salva suas informa√ß√µes. Threads passam pelos mesmos estados que um processo.

A grande diferen√ßa entre subprocessos e threads √© em rela√ß√£o ao espa√ßo de endere√ßamento.

Subprocessos possuem, cada um, espa√ßos independentes e protegidos.

Threads, por outro lado, compartilham o mesmo espa√ßo de endere√ßamento do processo, sem nenhuma prote√ß√£o, permitindo que um thread possa alterar dados de outro thread. S√£o desenvolvidos para trabalharem de forma cooperativa, voltados para desempenhar uma tarefa em conjunto, e s√£o conhecidos como processos leves.

A mudan√ßa de contexto entre threads em um mesmo processo exige uma altera√ß√£o de um conjunto de registradores, mas n√£o √© necess√°rio nenhum outro trabalho, como gerenciamento de mem√≥ria, por exemplo, tornando-a mais leve que a mudan√ßa de contexto entre processos.


Quando m√∫ltiplos threads est√£o presentes no mesmo processo, alguns campos da tabela de processos n√£o ocorrem por processo, mas por thread.

Em alguns sistemas, os threads s√£o gerenciados no espa√ßo do usu√°rio, sem o conhecimento do sistema operacional. √â o caso do pacote P-threads (POSIX). A comuta√ß√£o de threads √© muito mais r√°pida quando √© feita no espa√ßo do usu√°rio pelo fato de n√£o precisar fazer uma chamada ao kernel. Por√©m, quando os threads s√£o executados no espa√ßo do usu√°rio e um thread bloqueia, todo o processo √© bloqueado pelo kernel. Threads no n√≠vel do usu√°rio tamb√©m fazem com que o tempo dedicado a threads de diferentes processos n√£o seja distribu√≠do de forma justa.

Aten√ß√£o
Threads s√£o muito √∫teis em sistemas com m√∫ltiplas UCP, nos quais o paralelismo real √© poss√≠vel. Elas permitem que ocorram m√∫ltiplas execu√ß√µes no mesmo ambiente, fazendo com que v√°rias partes de um mesmo processo estejam em execu√ß√£o concorrente em diferentes processadores.



O termo multithread tamb√©m √© usado para descrever a permiss√£o de m√∫ltiplos threads no mesmo processo. Algumas UCP oferecem suporte de hardware direto para multithread e permitem que chaveamentos de threads aconte√ßam em uma escala de tempo de nanossegundos.

Processos com apenas um thread s√£o conhecidos como monothread.

Al√©m de compartilhar o espa√ßo de endere√ßamento, os threads podem compartilhar o mesmo conjunto de arquivos abertos, processos filhos, alarmes e sinais.

Aten√ß√£o
√â importante perceber que cada thread tem a sua pr√≥pria pilha, que cont√©m uma estrutura para cada rotina chamada, mas ainda n√£o retornada. Essa estrutura cont√©m as vari√°veis locais da rotina e o endere√ßo de retorno para serem usados quando a chamada de rotina for encerrada.

---------------
No Linux, os threads s√£o criados com a chamada de sistema clone(). Sua sintaxe √©:


int clone(int (*fn)(void *), void *stack, int flags, void *arg);

Descri√ß√£o dos Par√¢metros
fn: fun√ß√£o a ser executada pelo novo thread/processo.

stack: ponteiro para o topo da pilha do novo thread/processo.

flags: flags que definem o comportamento do clone().

arg: argumento passado para a fun√ß√£o fn.

Flags comuns do clone()
FLAG	Quando utilizado	Quando n√£o utilizado
CLONE_VM	Cria uma thread (compartilha espa√ßo de mem√≥ria).	Cria um novo processo (espa√ßo de mem√≥ria separado).
CLONE_FS	Compartilha informa√ß√µes do sistema de arquivos.	Cada processo/thread tem suas pr√≥prias informa√ß√µes.
CLONE_FILES	Compartilha descritores de arquivos.	Cada um possui c√≥pias independentes dos descritores.
CLONE_SIGHAND	Compartilha a tabela de tratadores de sinais.	Cada um possui sua pr√≥pria tabela de sinais.
CLONE_PARENT	Novo thread tem o mesmo pai que o chamador.	O chamador √© o pai do novo thread/processo.
SIGCHLD	O thread envia o sinal SIGCHLD ao pai ao terminar.	O thread n√£o envia SIGCHLD ao pai ao terminar.

Exemplo de programa em C com uso de clone()
Esse exemplo cria tr√™s threads dentro de um processo. A fun√ß√£o funcaoThread() ser√° executada por cada um deles. A thread principal espera todos os threads finalizarem antes de terminar sua pr√≥pria execu√ß√£o.


#define _GNU_SOURCE
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sched.h>
#include <sys/wait.h>

#define TAMANHO_PILHA 65536
#define _1SEGUNDO 1000000

int global = 0; // Vari√°vel global alterada pelos threads

static int funcaoThread(void *arg) {
    int id = *((int *) arg); // Identifica√ß√£o de cada thread
    int i;

    printf("Iniciou thread [%d]\n", id);
    for (i = 0; i < 3; i++) { // Loop no qual o thread altera a vari√°vel global
        printf("Thread [%d] incrementou \"global\" para %d.\n", id, ++global);
        usleep(_1SEGUNDO * (1 + id / 10.0));
    }
    printf("Saindo do thread [%d]\n", id);
    return 0;
}

int main() {
    void *pilha;
    int i, pid[3];
    int id[3] = {1, 2, 3}; // Identifica√ß√£o a ser passada para cada thread

    for (i = 0; i < 3; i++) {
        // Alocando espa√ßo para a pilha de cada thread
        if ((pilha = malloc(TAMANHO_PILHA)) == 0) {
            perror("Erro na aloca√ß√£o da pilha.");
            exit(1);
        }

        // Cria√ß√£o de cada thread
        pid[i] = clone(
            funcaoThread,
            pilha + TAMANHO_PILHA,
            CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND | SIGCHLD,
            &(id[i])
        );
    }

    printf("Thread principal aguardando demais threads terminarem.\n");
    for (i = 0; i < 3; i++) {
        if (waitpid(pid[i], 0, 0) == -1) { // Aguarda at√© o t√©rmino do thread
            perror("waitpid");
            exit(2);
        }
    }

    printf("Thread principal terminando.\n\n");
    return 0;
}

--------------------

Quando executado, o programa fornece a seguinte sa√≠da:

  
Thread principal aguardando demais threads terminarem.
Iniciou thread [3]
Thread [3] incrementou "global" para 1.
Iniciou thread [2]
Thread [2] incrementou "global" para 2.
Iniciou thread [1]
Thread [1] incrementou "global" para 3.
Thread [1] incrementou "global" para 4.
Thread [2] incrementou "global" para 5.
Thread [3] incrementou "global" para 6.
Thread [1] incrementou "global" para 7.
Thread [2] incrementou "global" para 8.
Thread [3] incrementou "global" para 9.
Saindo do thread [1]
Saindo do thread [2]
Saindo do thread [3]
Thread principal terminando.
Pela execu√ß√£o, voc√™ pode perceber que os valores das vari√°veis locais de cada thread n√£o s√£o influenciados pela execu√ß√£o dos demais threads. Por√©m, quando a vari√°vel ‚Äúglobal‚Äù √© modificada por um thread, esta altera√ß√£o √© vista imediatamente por todos os demais threads.

Tipos de processos
Existem basicamente dois tipos de processos relacionados ao tipo de processamento que executam. Nos cards, a seguir, entenda cada um deles:

Os processos do tipo CPU-bound passam a maior parte do tempo no estado executando, realizando poucas opera√ß√µes de E/S. Costumam ser encontrados em aplica√ß√µes cient√≠ficas.

Os processos do tipo I/O-bound passam a maior parte do tempo no estado bloqueado, por realizar elevado n√∫mero de opera√ß√µes de E/S. Costumam ser encontrados em aplica√ß√µes comerciais. Processos interativos tamb√©m s√£o exemplos deste tipo de processo.



Processos e threads no Linux
O Linux pode duplicar um processo por meio da chamada de sistema fork(), mas tamb√©m pode criar threads pela chamada de sistema clone(). No entanto, ele n√£o faz distin√ß√£o entre processos e threads. Toda entidade em execu√ß√£o, processo ou thread, ser√° considerada como uma tarefa (task). Um processo com um √∫nico thread ser√° considerado como uma tarefa, e um processo com n threads ter√° n estruturas de tarefas.

Aten√ß√£o
As chamas de sistema fork() e clone() s√£o bastante semelhantes. De fato, se clone() for invocada sem nenhum flag passado como par√¢metro, seu comportamento ser√° id√™ntico ao fork().

O contexto de uma tarefa do Linux n√£o √© mantido em uma √∫nica estrutura, mas s√£o criadas v√°rias estruturas independentes para cada contexto. Os dados de uma tarefa s√£o acessados por meio de ponteiros que apontam para cada estrutura de cada contexto. Dessa forma, o compartilhamento de informa√ß√µes entre as tarefas fica facilitado, bastando que as tarefas apontem para as mesmas estruturas em mem√≥ria.

A fim de manter a compatibilidade com demais sistemas UNIX, o Linux associa um PID diferente a cada tarefa. Desta forma, diferentes threads de um processo ter√£o diferentes PID.

Quando um subprocesso √© criado, a princ√≠pio, o Linux deveria alocar mem√≥ria para os diferentes processos e copiar o conte√∫do dos segmentos de mem√≥ria do processo pai. Por√©m, copiar segmentos de mem√≥ria requer processamento e toma tempo. Ent√£o, para ser mais eficiente, o Linux simplesmente faz com que ambos (pai e filho) compartilhem o mesmo segmento de mem√≥ria.


Se os processos se limitarem √† opera√ß√£o de consulta nos segmentos, n√£o haver√° problema, mas, se algum dos processos tentar escrever em um dos segmentos, neste momento, haver√° a c√≥pia do segmento compartilhado (mecanismo conhecido como c√≥pia na escrita ‚Äì copy on write). Al√©m de aumentar o desempenho do sistema, esse mecanismo ajuda a diminuir o consumo de mem√≥ria f√≠sica.

Qual √© a vantagem dos threads gerenciados no espa√ßo do usu√°rio?

Alternativas:

A) A comuta√ß√£o de threads √© mais r√°pida. ‚úÖ

B) O tempo dedicado a threads de diferentes processos √© distribu√≠do de forma mais justa.

C) Promover√° uma concorr√™ncia real entre os threads do processo.

D) Quando um thread bloqueia, os demais threads do processo n√£o s√£o bloqueados.

Coment√°rio:
A alternativa A est√° correta. Quando os threads s√£o gerenciados no espa√ßo do usu√°rio (user-level threads), a comuta√ß√£o entre eles √© feita sem precisar de interven√ß√£o do kernel, tornando o context switch mais r√°pido. Por√©m, se um thread fizer uma chamada bloqueante ao sistema, todos os outros threads do processo podem ser bloqueados, pois o kernel n√£o tem visibilidade individual de cada thread.

2. Processos e threads s√£o conceitos fundamentais para o desenvolvimento de sistemas concorrentes.
Pergunta:
Sobre processos e threads no Linux, indique a alternativa correta.

Alternativas:

A) O Linux n√£o diferencia processos de threads, tratando tudo como uma tarefa. ‚úÖ

B) Por quest√µes de desempenho, todo o contexto de uma tarefa √© mantido em uma √∫nica estrutura.

C) Quando um subprocesso √© criado, o Linux copia imediatamente os segmentos de mem√≥ria do processo pai para o processo filho.

D) Threads que fazem parte de um mesmo processo possuem o mesmo PID.

Coment√°rio:
A alternativa A est√° correta. No Linux, tanto threads quanto processos s√£o representados por uma estrutura de tarefa chamada task_struct. O sistema os diferencia com base nas flags utilizadas na cria√ß√£o (por exemplo, com clone()), mas ambos s√£o considerados "tarefas" pelo kernel. Threads do mesmo processo compartilham recursos (mem√≥ria, arquivos etc.), mas t√™m PIDs distintos.

----------------

M√ìDULO 3 - Identificar o mecanismo de comunica√ß√£o entre processos


PROCESSOS DE APLICA√á√ïES CONCORRENTES
O surgimento dos sistemas multiprogram√°veis tornou poss√≠vel criar aplica√ß√µes nas quais diferentes partes do c√≥digo de um programa pudessem executar de forma concorrente. Tais aplica√ß√µes s√£o conhecidas como aplica√ß√µes concorrentes.

√â comum que processos de aplica√ß√µes concorrentes compartilhem recursos do sistema. N√£o importam quais recursos s√£o compartilhados, os problemas decorrentes ser√£o os mesmos. O compartilhamento de recursos entre processos pode gerar situa√ß√µes indesej√°veis capazes de comprometer o sistema.

Se dois processos concorrentes trocam informa√ß√µes atrav√©s de um buffer, um deles s√≥ poder√° gravar dados caso o buffer n√£o esteja cheio, enquanto um processo s√≥ poder√° ler dados caso o buffer n√£o esteja vazio. Em qualquer caso, os processos dever√£o aguardar at√© que o buffer esteja pronto para as opera√ß√µes de E/S.

As considera√ß√µes anteriores levam a tr√™s quest√µes:


Como um processo passa informa√ß√µes a outro?


Como garantir que dois processos n√£o se interfiram?


Como realizar o sequenciamento quando um processo depende do outro?

√â bastante comum que aplica√ß√µes concorrentes necessitem trocar informa√ß√µes. Tal comunica√ß√£o pode se dar por meio de vari√°veis compartilhadas (mem√≥ria compartilhada) ou por troca de mensagens. Por√©m, independentemente do mecanismo de comunica√ß√£o utilizado, √© preciso que os processos possam se manter sincronizados.


Aten√ß√£o
Os mecanismos que garantem a comunica√ß√£o entre processos concorrentes e o acesso a recursos compartilhados s√£o chamados mecanismos de sincroniza√ß√£o. Os mesmos mecanismos se aplicam a threads.

CONDI√á√ÉO DE CORRIDA
Em alguns sistemas, processos que est√£o trabalhando em conjunto, muitas vezes, utilizam uma mem√≥ria comum, onde cada processo pode ler ou escrever. Este armazenamento compartilhado pode ser feito na mem√≥ria principal ou em um arquivo em disco.

Exemplo - Imagine um programa que atualize o saldo de um cliente ap√≥s o lan√ßamento de um d√©bito ou um cr√©dito em um registro.

O trecho do programa que faz a atualiza√ß√£o poderia ser:

  
void atualiza_saldo(double valor, int conta) {
Registro registro;
registro = le_registro(conta);
registro.saldo = registro.saldo + valor;
grava_registro(registro, conta);
}


Exemplo
Suponha que os funcion√°rios Carlos e Orlando, caixas do banco, solicitem a atualiza√ß√£o de uma conta cujo saldo √© 500. Carlos faz uma opera√ß√£o de dep√≥sito de 100 e Orlando uma opera√ß√£o de saque de 200. Pode acontecer de o processo de Carlos ler o saldo da conta (500) e, ao mesmo tempo, o processo de Orlando ler o mesmo valor. Ent√£o, o processo de Carlos soma 100 e grava o registro com o valor 600. No entanto, o processo de Orlando j√° tem o valor de saldo de 500, subtrai 200 e fica com saldo de 300. Como o processo de Orlando grava o registro por √∫ltimo, o dep√≥sito n√£o √© computado, levando a uma inconsist√™ncia. O valor final das opera√ß√µes deveria ser 400, mas ficou registrado 300.

Problemas como esses s√£o conhecidos como condi√ß√£o de corrida, que ocorre quando dois ou mais processos est√£o acessando dados compartilhados e o resultado do processamento depende de quem executa e quando √© executado.

----------------------

Regi√£o cr√≠tica
Como evitar as condi√ß√µes de corrida?

A forma mais simples √© impedir que dois ou mais processos acessem um mesmo recurso no mesmo instante, impedindo que eles acessem o recurso compartilhado simultaneamente. Quando um processo estiver acessando o recurso, os demais dever√£o esperar. A esta exclusividade de acesso d√°-se o nome de exclus√£o m√∫tua, uma quest√£o importante para o desenvolvimento de um sistema operacional.

A parte do programa que acessa a mem√≥ria compartilhada √© denominada se√ß√£o cr√≠tica ou regi√£o cr√≠tica (RC). Quando um processo √© executado dentro de sua regi√£o cr√≠tica, nenhum outro processo pode entrar l√°.

  
{
......
Entra_Regiao_Critica();
Executa_Regiao_Critica();
Sai_Regiao_Critica();
......
}


N√£o √© suficiente evitar que o processo seja interrompido dentro da regi√£o cr√≠tica. S√£o quatro as condi√ß√µes para uma boa solu√ß√£o:

1. N√£o pode haver mais de um processo simultaneamente dentro de suas regi√µes cr√≠ticas.

2. Nenhuma suposi√ß√£o pode ser feita sobre a velocidade ou o n√∫mero de UCP.

3. Nenhum processo que execute fora de sua regi√£o cr√≠tica pode bloquear outro processo.

4. Nenhum processo deve ter de esperar eternamente para entrar em sua regi√£o cr√≠tica (starvation).

Para garantir a implementa√ß√£o da exclus√£o m√∫tua, os processos envolvidos devem fazer acesso aos recursos compartilhados de forma sincronizada.

Sem√°foros
Um sem√°foro √© uma vari√°vel inteira que conta sinais enviados a ela. Associadas aos sem√°foros, existem duas opera√ß√µes especiais: up e down.

A opera√ß√£o down decrementa o valor do sem√°foro se ele for maior que 0, sen√£o o processo √© bloqueado.

A opera√ß√£o up incrementa o valor do sem√°foro caso n√£o haja processos que tenham sido bloqueados pela opera√ß√£o down, sen√£o um processo √© desbloqueado.

No caso da exclus√£o m√∫tua, as instru√ß√µes down e up funcionam como protocolos para que um processo possa entrar e sair de sua regi√£o cr√≠tica. O sem√°foro fica associado a um recurso compartilhado, indicando quando o recurso est√° sendo acessado por um dos processos concorrentes. Se seu valor for maior que 0, nenhum processo est√° utilizando o recurso. Caso contr√°rio, o processo fica impedido de acessar o recurso.

Sempre que deseja entrar na sua regi√£o cr√≠tica, um processo executa uma instru√ß√£o down. Se o sem√°foro for maior que 0, ele √© decrementado de 1, e o processo que solicitou a opera√ß√£o pode executar sua regi√£o cr√≠tica. Se uma instru√ß√£o down √© executada em um sem√°foro cujo valor seja 0, o processo que solicitou a opera√ß√£o ficar√° no estado bloqueado em uma fila associada ao sem√°foro.

Quando o processo que est√° acessando o recurso sai de sua regi√£o cr√≠tica, ele executa uma instru√ß√£o up, incrementando o sem√°foro de 1 e liberando o acesso ao recurso. Se um ou mais processos estiverem esperando, o sistema escolhe um processo na fila de espera e muda seu estado para pronto.

As opera√ß√µes up e down s√£o realizadas pelo sistema operacional, que deve garantir que elas sejam executadas atomicamente.

A corre√ß√£o para o caso anterior de atualiza√ß√£o do saldo de uma conta, com a utiliza√ß√£o de sem√°foros, ficaria:

  
void atualiza_saldo(double valor, int conta) {
Registro registro;
down(mutex);
registro = le_registro(conta);
registro.saldo = registro.saldo + valor;
grava_registro(registro, conta);
up(mutex);
}

-----------------


Com a utiliza√ß√£o de sem√°foros, somente um dos processos estar√° dentro da regi√£o cr√≠tica em determinado instante. Voltemos ao caso dos caixas Carlos e Orlando:

Exemplo
Ambos solicitaram a atualiza√ß√£o de uma conta cujo saldo √© 500. Com a utiliza√ß√£o de sem√°foros, antes de o processo de Carlos ler o saldo, √© realizada a opera√ß√£o down(mutex). Supondo que n√£o haja outro processo na regi√£o cr√≠tica, o sem√°foro mutex permitir√° a entrada do processo de Carlos. Quando o processo de Orlando tenta fazer sua opera√ß√£o, tamb√©m se chamar√° down(mutex), mas, como o processo de Carlos est√° na regi√£o cr√≠tica, o processo de Orlando ser√° bloqueado pelo sem√°foro. O processo de Carlos segue normalmente, faz o dep√≥sito de 100 e atualiza o saldo para 600. Ao sair da regi√£o cr√≠tica, o processo de Carlos faz up(mutex), liberando o processo de Orlando, que faz a leitura do saldo j√° atualizado (600). Assim, o processo faz o saque de 200 e atualiza o saldo para 400. Ao final, o processo de Orlando faz up(mutex), liberando novamente a regi√£o cr√≠tica. Vemos que, com a utiliza√ß√£o de sem√°foros, n√£o ocorre a inconsist√™ncia vista anteriormente.

Para conhecer os programas em Linguagem C para Linux que fazem opera√ß√µes concorrentes de saque e dep√≥sito, consulte o documento Utiliza√ß√£o de sem√°foro na solu√ß√£o de condi√ß√£o de corrida.

Monitores
O uso de sem√°foros exige do programador muito cuidado, pois qualquer engano pode levar a problemas de sincroniza√ß√£o imprevis√≠veis e dif√≠ceis de reproduzir. Monitores s√£o mecanismos de sincroniza√ß√£o de alto n√≠vel que tentam tornar mais f√°ceis o desenvolvimento e a corre√ß√£o de programas concorrentes.

Um monitor √© uma cole√ß√£o de vari√°veis, procedimentos e estruturas de dados que s√£o agrupados em um pacote. Em determinado instante, somente um processo pode estar ativo em um monitor. Toda vez que algum processo chama um procedimento do monitor, ele verifica se j√° existe outro processo executando qualquer procedimento do monitor. Caso exista, o processo ficar√° aguardando a sua vez, at√© que tenha permiss√£o para executar.


As vari√°veis globais do monitor s√£o vis√≠veis apenas a ele e a seus procedimentos. O bloco de comandos do monitor √© respons√°vel por inicializar essas vari√°veis, sendo executado apenas uma vez na ativa√ß√£o do programa onde est√° declarado o monitor.

Cabe ao compilador implementar as exclus√µes m√∫tuas em entradas de monitor. A cl√°usula synchronized da linguagem Java √© um exemplo de implementa√ß√£o de monitores. O programador transforma regi√µes cr√≠ticas em procedimentos de monitor, colocando todas as regi√µes cr√≠ticas em forma de procedimentos no monitor. Assim, o desenvolvimento de programas concorrentes fica mais f√°cil.


SINCRONIZA√á√ÉO NO LINUX
O Linux oferece suporte √† utiliza√ß√£o de sem√°foros para sincroniza√ß√£o de tarefas por meio da chamada de sistema sem_wait(), que realiza a opera√ß√£o up(), e da chamada de sistema sem_post(), que realiza a opera√ß√£o down().

Quando sem_wait() √© invocada e o valor do sem√°foro √© zero, a tarefa que faz a invoca√ß√£o √© bloqueada at√© que o sem√°foro seja liberado por meio da fun√ß√£o sem_post(). Por√©m, em algumas situa√ß√µes, a tarefa pode querer apenas verificar se √© poss√≠vel prosseguir, mas n√£o √© interessante bloquear, caso n√£o possa prosseguir.

Aten√ß√£o
Para esses casos, pode ser utilizada a chamada de sistema sem_trywait(), que tem funcionamento parecido com a sem_wait(), exceto pelo fato de que, se o decremento n√£o puder ser executado imediatamente, a chamada de sistema retorna um erro sem bloqueio.

Al√©m da utiliza√ß√£o de sem√°foros para sincroniza√ß√£o de processos, o Linux permite a comunica√ß√£o entre processos por meio de troca de mensagens e de sinais.

A troca de mensagens pode ser implementada pelo mecanismo de pipe. O pipe ( | ) √© um mecanismo especial de redirecionamento utilizado para conectar a sa√≠da padr√£o de um processo √† entrada padr√£o de outro processo. Por exemplo, os comandos a seguir juntam todos os arquivos com extens√£o ‚Äú.txt‚Äù, ordenando suas linhas e retirando as duplicadas.

  
cat *.txt | sort | uniq
Entenda o significado de cada um deles:

O comando ‚Äúcat *.txt‚Äù joga na sa√≠da padr√£o (tela) o conte√∫do de todos os arquivos presentes no diret√≥rio e que possuem extens√£o ‚Äú.txt‚Äù.

O comando ‚Äúsort‚Äù recebe linhas por sua entrada padr√£o (inicialmente, o teclado), ordena as linhas e envia as linhas devidamente ordenadas para a sa√≠da padr√£o.

O comando ‚Äúuniq‚Äù recebe linhas por sua entrada padr√£o e elimina as linhas duplicadas, enviando para a sa√≠da padr√£o somente as linhas que n√£o est√£o em duplicidade.

Quando √© utilizada a barra vertical ( | ) entre os comandos, √© introduzido um pipe entre as tarefas, ou seja, as tarefas s√£o colocadas em execu√ß√£o concorrente, e a sa√≠da padr√£o da tarefa √† esquerda do pipe √© conectada √† entrada padr√£o da tarefa √† direita do pipe. Assim, no exemplo, a sa√≠da do comando ‚Äúcat *.txt‚Äù √© enviada para a entrada do comando ‚Äúsort‚Äù, que faz a ordena√ß√£o, e sua sa√≠da √© enviada √† entrada do comando ‚Äúuniq‚Äù, que elimina as linhas repetidas e, finalmente, joga o resultado de seu processamento para a sa√≠da padr√£o (o monitor, por padr√£o).

Outra forma de comunica√ß√£o entre processos no Linux ocorre por meio de envio de sinais, que s√£o enviados na ocorr√™ncia de eventos, como a chegada de uma informa√ß√£o pela rede, o fim de um temporizador, o t√©rmino da execu√ß√£o de um processo filho etc. S√£o eventos que chegam ao processo e precisam ser tratados de alguma forma. Para isso, √© necess√°rio definir uma rotina para o tratamento do evento.

--------------------




 exemplos de sinais do Linux, suas a√ß√µes padr√£o e coment√°rios explicativos:

Sinal	A√ß√£o Padr√£o	Coment√°rio
SIGHUP	Terminar	Gerado quando o terminal controlador √© encerrado.
SIGTERM	Terminar	Solicita a termina√ß√£o graciosa do processo.
SIGINT	Terminar	Interrup√ß√£o do processo (geralmente via Ctrl+C).
SIGKILL	Terminar	For√ßa a finaliza√ß√£o imediata do processo; n√£o pode ser capturado ou ignorado.
SIGTSTP	Suspender	Suspende o processo (geralmente via Ctrl+Z); pode ser capturado ou ignorado.
SIGSTOP	Suspender	Suspende o processo; n√£o pode ser capturado ou ignorado.
SIGCONT	Continuar	Retoma a execu√ß√£o de um processo suspenso.
SIGCHLD	Ignorar	Indica que um processo filho terminou ou foi suspenso.
SIGALRM	Terminar	Indica que o temporizador definido por alarm() expirou.
SIGURG	Ignorar	Indica dados urgentes dispon√≠veis em um socket.
SIGUSR1	Terminar	Sinal definido pelo usu√°rio para uso geral.
SIGUSR2	Terminar	Outro sinal definido pelo usu√°rio para uso geral.

Nota: Os sinais SIGKILL e SIGSTOP s√£o especiais, pois n√£o podem ser capturados, bloqueados ou ignorados pelo processo.

---------------
Comportamento de um Processo ao Receber um Sinal
Comportamento	Descri√ß√£o
A√ß√£o padr√£o	O processo executa a a√ß√£o predefinida pelo kernel para o sinal recebido.
Captura do sinal	O processo define uma fun√ß√£o espec√≠fica para tratar o sinal.
Ignorar o sinal	O processo opta por n√£o reagir ao sinal.
Sinais n√£o manipul√°veis	SIGKILL e SIGSTOP n√£o podem ser capturados ou ignorados .
-----------
Fontes de Gera√ß√£o de Sinais
Origem	Exemplo
Exce√ß√µes de hardware	Falha de segmenta√ß√£o (SIGSEGV), divis√£o por zero (SIGFPE).
Condi√ß√µes de software	Erros detectados pelo sistema operacional ou pelo pr√≥prio programa.
Comando kill no shell	Envio de sinais para processos espec√≠ficos.
Chamada de sistema kill()	Um processo envia sinais para outro processo.
Combina√ß√µes de teclas	Ctrl+C envia SIGINT, Ctrl+Z envia SIGTSTP.
Controle de processos	Sinais enviados para gerenciar o estado de processos (suspender, continuar).
-------------
Principais Chamadas de Sistema para Tratamento de Sinais
Chamada de Sistema	Descri√ß√£o
signal()	Instala uma rotina para tratamento de um sinal espec√≠fico.
sigaction()	Define a a√ß√£o a ser tomada quando um sinal √© recebido.
sigreturn()	Retorna de um manipulador de sinal para o ponto de interrup√ß√£o.
sigpending()	Obt√©m o conjunto de sinais que est√£o bloqueados e pendentes.
kill()	Envia um sinal para um processo ou grupo de processos.
alarm()	Agenda o envio de um sinal (SIGALRM) ap√≥s um determinado tempo.
pause()	Suspende a execu√ß√£o do processo at√© que um sinal seja recebido.

--------------------
1. Dos mecanismos de sincroniza√ß√£o/comunica√ß√£o entre processos listados, selecione aquele que n√£o √© implementado diretamente pelo sistema operacional Linux:
( ) Sem√°foros

( ) Sinais

( ) Troca de mensagens

(X) Monitores

Coment√°rio:
Monitores s√£o uma abstra√ß√£o de sincroniza√ß√£o de alto n√≠vel geralmente implementada por linguagens de programa√ß√£o (como Java), e n√£o diretamente pelo kernel do Linux. Os demais mecanismos (sem√°foros, sinais, troca de mensagens) s√£o implementados pelo sistema operacional.

2. A condi√ß√£o de corrida √© um problema que deve ser evitado, pois pode levar √† inconsist√™ncia nos dados do sistema. A condi√ß√£o de corrida ocorre quando:
( ) Dois processos disputam para determinar quem termina primeiro

( ) √â realizada tentativa de acesso a uma regi√£o cr√≠tica bloqueada por um sem√°foro

(X) Tarefas concorrentes podem alterar o mesmo dado

( ) Threads s√£o criadas executando a mesma fun√ß√£o

Coment√°rio:
A condi√ß√£o de corrida ocorre quando dois ou mais processos ou threads acessam e manipulam dados compartilhados simultaneamente, e o resultado depende da ordem de execu√ß√£o. Isso pode gerar comportamentos imprevis√≠veis e erros.

----------------

tema 3 - M√ìDULO 4 - Comparar as diferentes formas de escalonamento


ESCALONAMENTO
A multiprograma√ß√£o tem como objetivo permitir que, a todo instante, haja algum processo para maximizar a utiliza√ß√£o da UCP.

O conceito que possibilitou a implementa√ß√£o de sistemas multiprogram√°veis foi a possibilidade de a UCP ser compartilhada entre diversos processos. Portanto, deve existir um crit√©rio para determinar a ordem da escolha dos processos para execu√ß√£o dentre os v√°rios que concorrem pela UCP.

O procedimento de sele√ß√£o √© conhecido como escalonamento (scheduling). A parte do sistema operacional respons√°vel pelo escalonamento √© o escalonador (scheduler), √†s vezes chamado de agendador. Sempre que a UCP se torna ociosa, o escalonador seleciona um processo dentre aqueles que est√£o na mem√≥ria prontos para serem executados (na fila de processos no estado pronto) e aloca a UCP para que ele possa ser executado.

A principal fun√ß√£o de um algoritmo de escalonamento √© decidir qual dos processos prontos deve ser alocado √† UCP.

O algoritmo de escalonamento n√£o √© o √∫nico respons√°vel pelo tempo de execu√ß√£o de um processo. Ele afeta somente o tempo de espera na fila de processos prontos, e pode ser classificado como preemptivo ou n√£o preemptivo. Quando o sistema pode interromper um processo durante sua execu√ß√£o para coloc√°-lo no estado pronto e colocar outro processo no estado executando, tem-se um sistema preemptivo. Caso contr√°rio, h√° um sistema n√£o preemptivo.

Realizar o escalonamento preemptivo exige que uma interrup√ß√£o de rel√≥gio ocorra ao fim do intervalo para devolver o controle da UCP ao escalonador.

A troca de um processo por outro na UCP (mudan√ßa de contexto) causada pela preemp√ß√£o gera um overhead ao sistema. Para n√£o se tornar cr√≠tico, o sistema deve estabelecer corretamente os crit√©rios de preemp√ß√£o.

Aten√ß√£o
Sistemas que usam escalonamento preemptivo t√™m o problema da condi√ß√£o de corrida, o que n√£o ocorre com sistemas que usam escalonamento n√£o preemptivo. No escalonamento n√£o preemptivo, quando um processo ganha o direito de utilizar a UCP, nenhum outro processo pode tirar dele esse recurso.

A seguir, conhe√ßa os tipos de escalonamento:

Clique nas barras para ver as informa√ß√µes.
Escalonamento First In First Out (FIFO)  - Algoritmo de escalonamento tamb√©m conhecido como primeiro a chegar, primeiro a ser servido (first come, first served).

A grande for√ßa deste algoritmo √© que ele √© f√°cil de aprender e de programar.

Nesse escalonamento, o processo que chegar primeiro √© o primeiro a ser selecionado para execu√ß√£o. √â preciso apenas uma fila, em que os processos que passam para o estado pronto entram no seu final. Quando um processo ganha a UCP, ele a utiliza sem ser interrompido, caracterizando-o como um algoritmo n√£o preemptivo.

O problema do escalonamento FIFO √© a impossibilidade de se prever quando um processo ter√° sua execu√ß√£o iniciada. Outro problema √© a possibilidade de processos CPU-bound de menor import√¢ncia prejudicarem processos I/O-bound mais priorit√°rios.

Este algoritmo foi inicialmente implementado em sistemas batch.
----------


Escalonamento Shortest Job First (SJF) - O algoritmo SJF (tarefa mais curta primeiro) associa a cada processo seu tempo de execu√ß√£o. Quando a UCP est√° livre, o processo no estado pronto que precisar de menos tempo para terminar √© selecionado para execu√ß√£o.

O escalonamento SJF beneficia processos que necessitam de pouco processamento e reduzem o tempo m√©dio de espera em rela√ß√£o ao FIFO. O problema √© determinar quanto tempo de UCP cada processo necessita para terminar seu processamento. Em ambientes de produ√ß√£o, √© poss√≠vel estimar o tempo de execu√ß√£o, mas, em ambientes de desenvolvimento, √© muito dif√≠cil.

Imagine quatro tarefas A, B, C e D com tempos de execu√ß√£o de 14, 8, 6 e 4 minutos, respectivamente. Ao execut√°-las nessa ordem, o tempo de retorno para A √© 14 minutos, para B, 22 minutos, para C, 28 minutos e, para D, 32 minutos, resultando em uma m√©dia de 24 minutos. Agora, considere executar essas quatro tarefas usando o algoritmo da tarefa mais curta primeiro. Os tempos de retorno s√£o agora 4, 10, 18 e 32 minutos, o que resulta em uma m√©dia de 16 minutos.

√â um algoritmo de escalonamento n√£o preemptivo e, assim como o FIFO, tamb√©m foi utilizado nos primeiros sistemas operacionais com processamento batch.
--------------------


Escalonamento Shortest Remaining Time Next (SRTN) - O SRTN (tempo restante mais curto em seguida) √© uma vers√£o preemptiva do SJF. Nele, o escalonador escolhe o processo cujo tempo de execu√ß√£o restante √© o mais curto. Para o seu funcionamento, o tempo de execu√ß√£o precisa ser conhecido antecipadamente.

Quando uma nova tarefa chega, seu tempo total √© comparado ao tempo restante do processo atual. Se a nova tarefa precisar de menos tempo para terminar do que o processo atual, ela √© suspensa, e a nova tarefa √© iniciada. Esse esquema permite que novas tarefas curtas tenham um bom desempenho.
-------------------


Escalonamento cooperativo - O SJF e o FIFO n√£o s√£o algoritmos de escalonamento aplic√°veis a sistemas de tempo compartilhado, onde um tempo de resposta razo√°vel deve ser garantido a usu√°rios interativos.

No escalonamento cooperativo, quando um processo j√° est√° em execu√ß√£o por determinado tempo, ele voluntariamente libera a UCP, retornando para a fila de processos prontos.

Sua principal caracter√≠stica est√° no fato de a libera√ß√£o da UCP ser uma tarefa realizada exclusivamente pelo processo em execu√ß√£o, que a libera para um outro processo. N√£o existe nenhuma interven√ß√£o do sistema operacional na execu√ß√£o do processo. Isto pode ocasionar s√©rios problemas na medida em que um programa pode n√£o liberar a UCP ou um programa mal escrito pode entrar em loop, monopolizando a UCP.

√â um algoritmo de escalonamento n√£o preemptivo.
-------------------------



Escalonamento circular (Round Robin) - Esse algoritmo √© bem semelhante ao FIFO. Entretanto, quando um processo passa para o estado executando, existe um tempo limite (conhecido como time-slice ou quantum) para utiliza√ß√£o da UCP de forma cont√≠nua. Quando esse tempo expira, o processo volta ao estado pronto, dando a vez a outro processo.

A fila de processos no estado pronto √© tratada como uma fila circular. O escalonamento √© realizado alocando a UCP para cada processo da fila no intervalo de tempo determinado pelo quantum.

Se o quantum for muito pequeno, gasta-se muito tempo de UCP com trabalho administrativo. Se o quantum for muito grande, a interatividade fica prejudicada, j√° que um processo que sai de execu√ß√£o pode demorar muito a voltar. Em geral, o quantum varia de 10 a 100ms.

Atrav√©s do escalonamento circular, nenhum processo poder√° monopolizar a UCP, caracterizando-o como um algoritmo de escalonamento preemptivo.


Um problema do escalonamento circular √© que ele n√£o oferece qualquer tratamento diferenciado a processos I/O-bound. Assim, processos CPU-bound ter√£o a tend√™ncia de monopolizar a utiliza√ß√£o da UCP, enquanto processos I/O-bound permanecem √† espera.
------------------------



Escalonamento por prioridade - O escalonamento circular consegue melhorar a distribui√ß√£o do tempo de UCP em rela√ß√£o aos escalonamentos n√£o preemptivos, por√©m ainda n√£o consegue implementar um compartilhamento equitativo entre os diferentes tipos de processos.

Para solucionar esse problema, os processos I/O-bound devem levar alguma vantagem no escalonamento, a fim de compensar o tempo excessivo gasto no estado bloqueado. Como alguns processos devem ser tratados de maneira diferente dos outros, √© preciso associar a cada um deles uma prioridade de execu√ß√£o. Assim, processos de maior prioridade s√£o escalonados preferencialmente.

A preemp√ß√£o por prioridade √© implementada mediante um rel√≥gio que interrompe o processador periodicamente, para que a rotina de escalonamento reavalie prioridades e, possivelmente, escalone outro processo, caracterizando-o como um algoritmo de escalonamento preemptivo.

Todos os sistemas de tempo compartilhado implementam algum esquema de prioridade, que √© uma caracter√≠stica do contexto de software de um processo, podendo ser est√°tica ou din√¢mica.

Tem-se a prioridade est√°tica quando a prioridade n√£o √© modificada durante a exist√™ncia do processo. Apesar da simplicidade de implementa√ß√£o, a prioridade est√°tica pode ocasionar tempos de resposta elevados.

Na prioridade din√¢mica, a prioridade do processo pode ser ajustada de acordo com o tipo de processamento realizado pelo processo ou pela carga do sistema. Quando o processo sai do estado bloqueado, recebe um acr√©scimo √† sua prioridade. Dessa forma, os processos I/O-bound ter√£o mais chance de ser escalonados e de compensar o tempo que passam no estado bloqueado.

Para evitar que processos com maior prioridade sejam executados indefinidamente, a prioridade √© diminu√≠da com o passar do tempo.

Outra forma de obter prioridade din√¢mica √© fazer com que o quantum do processo seja inversamente proporcional √† fra√ß√£o do √∫ltimo quantum utilizado.

Embora os sistemas de prioridade din√¢mica sejam mais complexos e gerem um overhead maior, o tempo de resposta oferecido compensa.
------------------------


Escalonamento por m√∫ltiplas filas - Como os processos de um sistema possuem diferentes caracter√≠sticas de processamento, √© dif√≠cil que um √∫nico mecanismo de escalonamento seja adequado a todos. Uma boa pol√≠tica seria classificar os processos em fun√ß√£o do tipo de processamento realizado e aplicar a cada grupo mecanismos de escalonamentos distintos.

O escalonamento por m√∫ltiplas filas implementa diversas filas de processo no estado pronto, onde cada processo √© associado exclusivamente a uma delas. Cada fila possui um mecanismo pr√≥prio de escalonamento em fun√ß√£o das caracter√≠sticas do processo. Nesse esquema, os processos devem ser classificados, previamente, em fun√ß√£o do tipo de processamento para poderem ser encaminhados √† determinada fila.

Cada fila possui uma prioridade associada, que estabelece quais s√£o priorit√°rias em rela√ß√£o √†s outras. O sistema s√≥ pode escalonar processos de uma fila se todas as outras filas de prioridade maior estiverem vazias.

Para exemplificar esse escalonamento, considere que os processos, em fun√ß√£o de suas caracter√≠sticas, sejam divididos em tr√™s grupos: sistema, interativo e batch. Os processos do sistema devem ser colocados em uma fila de prioridade superior aos outros processos, implementando um algoritmo de escalonamento baseado em prioridades. Os processos de usu√°rios interativos devem estar em uma fila de prioridade intermedi√°ria, implementando, por exemplo, o escalonamento circular. O mesmo mecanismo de escalonamento pode ser utilizado na fila de processos batch, com a diferen√ßa de que esta fila dever√° possuir uma prioridade mais baixa.
-------------------


Escalonamento em sistemas de tempo real - Um sistema de tempo real √© aquele em que o tempo tem um papel essencial. Tipicamente, um ou mais dispositivos f√≠sicos externos ao computador geram est√≠mulos. O computador tem de reagir em conformidade dentro de um montante de tempo fixo. Exemplos de sistemas de tempo real s√£o equipamentos que est√£o monitorando pacientes em uma UTI, o piloto autom√°tico de um avi√£o e o controle de rob√¥s em uma f√°brica automatizada. Em todos esses casos, ter a resposta certa tarde demais √©, muitas vezes, t√£o ruim quanto n√£o t√™-la.

Sistemas em tempo real geralmente s√£o categorizados como tempo real cr√≠tico, significando que h√° prazos absolutos que devem ser cumpridos, e tempo real n√£o cr√≠tico, significando que descumprir um prazo ocasional √© indesej√°vel, mas, mesmo assim, toler√°vel. Em ambos os casos, o comportamento em tempo real √© conseguido com a divis√£o do programa em uma s√©rie de processos, cada um dos quais √© previs√≠vel e conhecido antecipadamente. Esses processos geralmente t√™m vida curta e podem ser conclu√≠dos em curto espa√ßo de tempo. Quando um evento externo √© detectado, cabe ao escalonador programar os processos de maneira que todos os prazos sejam atendidos.

Os eventos a que um sistema de tempo real talvez tenha de responder podem ser categorizados ainda como peri√≥dicos (significando que eles ocorrem em intervalos regulares) ou aperi√≥dicos (significando que eles ocorrem de maneira imprevis√≠vel). Dependendo de quanto tempo cada evento exige para o processamento, tratar de todos talvez n√£o seja poss√≠vel. Se h√° m eventos peri√≥dicos e o evento i ocorre com o per√≠odo Pi e exige Ci segundos de tempo da UCP para lidar com cada evento, a carga s√≥ pode ser tratada se:

 
Diz-se de um sistema de tempo real que atende a esse crit√©rio que ele √© escalon√°vel, o que significa que ele realmente pode ser implementado. Um processo que n√£o atende a esse crit√©rio n√£o pode ser escalonado, pois o montante total de tempo de UCP que os processos querem coletivamente √© maior do que a UCP pode proporcionar.

Algoritmos de escalonamento de tempo real -  podem ser est√°ticos ou din√¢micos. Algoritmos est√°ticos tomam suas decis√µes de escalonamento antes de o sistema come√ßar a ser executado. Algoritmos din√¢micos tomam suas decis√µes no tempo de execu√ß√£o, ap√≥s ela ter come√ßado. O escalonamento est√°tico funciona apenas quando h√° uma informa√ß√£o perfeita dispon√≠vel antecipadamente sobre o trabalho a ser feito e sobre os prazos que precisam ser cumpridos. Algoritmos de escalonamento din√¢mico n√£o t√™m essas restri√ß√µes.
-------------------------



Escalonamento de threads - Quando v√°rios processos t√™m, cada um, m√∫ltiplos threads, h√° dois n√≠veis de paralelismo  presentes: processos e threads. O escalonamento nesses sistemas vai diferir, ainda, se s√£o threads de usu√°rio ou threads de n√∫cleo.

Sendo threads de usu√°rio, o n√∫cleo n√£o tem ci√™ncia da exist√™ncia dos threads. Assim, ele opera como sempre fez, escolhendo um processo A e dando a A o controle de seu quantum. O escalonador de thread dentro de A decide qual thread executar (A1, por exemplo). Dado que n√£o h√° interrup√ß√µes para multiprogramar threads, esse thread pode continuar a ser executado por quanto tempo quiser. Se ele utilizar todo o quantum do processo, o n√∫cleo selecionar√° outro processo para executar.

Quando o processo A executar novamente, o thread A1 retomar√° a execu√ß√£o. Ele continuar√° a consumir todo o tempo de A at√© que termine. No entanto, seu comportamento n√£o afetar√° outros processos. Eles receber√£o o que quer que o escalonador considere sua fra√ß√£o apropriada, n√£o importa o que estiver acontecendo dentro do processo A.

Agora, considere o caso em que os threads de A tenham relativamente pouco trabalho para fazer, por exemplo, 5ms de trabalho dentro de um quantum de 50ms. Em consequ√™ncia, cada um √© executado por um tempo. Ent√£o, cede a UCP de volta ao escalonador de threads. Isso pode levar √† sequ√™ncia A1, A2, A3, A1, A2, A3, A1, A2, A3, A1, antes que o n√∫cleo chaveie para o processo B.

O algoritmo de escalonamento usado pelo sistema de tempo de execu√ß√£o pode ser qualquer um dos descritos anteriormente. A √∫nica restri√ß√£o √© a aus√™ncia de um rel√≥gio para interromper um thread que esteja sendo executado h√° tempo demais. Como os threads cooperam, isso normalmente n√£o √© um problema.

Vejamos agora a situa√ß√£o com threads de n√∫cleo. Aqui, o n√∫cleo escolhe um thread em particular para executar. Ele n√£o precisa levar em conta a qual processo o thread pertence, mas pode fazer isso. O thread recebe um quantum e √© suspenso compulsoriamente se o exceder. Com um quantum de 50ms e threads que s√£o bloqueados ap√≥s 5ms, a ordem do thread por algum per√≠odo de 30ms pode ser A1, B1, A2, B2, A3, B3, algo que n√£o √© poss√≠vel com esses par√¢metros e threads de usu√°rio.

Uma diferen√ßa importante entre threads de usu√°rio e de n√∫cleo √© o desempenho. Realizar um chaveamento de thread com threads de usu√°rio exige um punhado de instru√ß√µes de m√°quina. Com threads de n√∫cleo, √© necess√°rio um chaveamento de contexto completo, mudar o mapa de mem√≥ria e invalidar o cache, o que representa uma demora bem maior. Por outro lado, com threads de n√∫cleo, ter um bloqueio de thread na E/S n√£o suspende todo o processo, como ocorre com threads de usu√°rio.

Como o n√∫cleo sabe que chavear de um thread no processo A para um thread no processo B √© mais caro do que executar um segundo thread no processo A, ele pode levar essa informa√ß√£o em conta quando toma uma decis√£o.

Outro fator importante √© que os threads de usu√°rio podem empregar um escalonador de thread espec√≠fico de uma aplica√ß√£o.

----------------------


ESCALONAMENTO NO LINUX
O Linux suporta a multitarefa preemptiva, em que o escalonador decide que processo deve ser executado e quando execut√°-lo. Tomar essas decis√µes de modo que mantenha o equil√≠brio entre justi√ßa e desempenho para muitas cargas de trabalho diferentes √© um dos desafios mais complicados dos sistemas operacionais modernos.

O Linux √© baseado em tarefas do n√∫cleo. S√£o definidas tr√™s classes de tarefas:

FIFO em tempo real

Escalonamento circular em tempo real

Tempo compartilhado

Entre essas tr√™s classes, √© utilizado um escalonamento por m√∫ltiplas filas, em que a classe FIFO em tempo real √© a fila de maior prioridade e a classe tempo compartilhado √© a classe de menor prioridade.

As tarefas FIFO em tempo real s√£o escalonadas exclusivamente por prioridade, sem preemp√ß√£o. Sempre que houver uma tarefa FIFO em tempo real, ela utilizar√° o processador sem ser interrompida, a n√£o ser que outra tarefa FIFO em tempo real de maior prioridade entre no estado pronto.

O escalonamento circular em tempo real funciona com algoritmo de escalonamento circular (Round Robin), com um quantum associado a cada tarefa. Sempre que uma tarefa excede seu quantum, ocorre uma preemp√ß√£o, e a tarefa √© colocada no final da fila de processos prontos.

Aten√ß√£o
Apesar do nome ‚Äútempo real‚Äù, nenhuma dessas classes √© realmente de tempo real, pois o sistema n√£o tem como garantir os limites de tempo necess√°rios ao funcionamento de um sistema de tempo real.

As tarefas de tempo real recebem prioridade de 0 a 99, sendo 0 o n√≠vel de prioridade mais alto e 99 o n√≠vel de prioridade mais baixo.

As tarefas de tempo compartilhado n√£o competem com as tarefas de tempo real. Elas s√£o escalonadas somente se n√£o houver nenhuma tarefa de tempo real no estado pronto. As tarefas de tempo compartilhado recebem prioridade de 100 a 139, sendo 100 a prioridade mais alta e 139 a prioridade mais baixa desta fila. Dessa forma, o Linux possui um total de 140 n√≠veis de prioridade.

Existe um utilit√°rio de linha de comando chamado nice, que pode ser utilizado para alterar a prioridade de uma tarefa. O nice recebe como par√¢metro um valor (de -20 a +19), que √© somado √† prioridade do thread. Apenas a conta root (administrator do Linux) pode fornecer um valor negativo como par√¢metro do nice. Isso significa que um usu√°rio comum pode solicitar apenas diminui√ß√£o na prioridade de suas tarefas, nunca aumento de prioridade.


1. Para selecionar a pr√≥xima tarefa a entrar em execu√ß√£o, o Linux utiliza o algoritmo de escalonamento:
( ) Cooperativo

( ) Tempo real

( ) Threads

(X) M√∫ltiplas filas

Coment√°rio:
O Linux utiliza um algoritmo de escalonamento baseado em m√∫ltiplas filas, permitindo lidar com diferentes classes de processos (interativos, em lote, tempo real, etc.), otimizando o desempenho e a responsividade do sistema.

2. Indique a principal caracter√≠stica de um algoritmo de escalonamento cooperativo:
( ) √â um algoritmo de escalonamento preemptivo

( ) N√£o existe risco de um processo monopolizar a UCP

(X) O processo em execu√ß√£o libera a UCP voluntariamente

( ) Os processos cooperam entre si por trocas de mensagens

Coment√°rio:
No escalonamento cooperativo, o controle da CPU permanece com o processo atual at√© que ele voluntariamente a libere. Isso pode causar problemas se o processo entrar em loop ou falhar, pois n√£o h√° preemp√ß√£o autom√°tica pelo sistema operacional.

------------------

conclus√£o  - Considera√ß√µes Finais

Iniciamos nosso estudo aprendendo sobre o modelo de processo, fundamental para implementa√ß√£o de sistemas de tempo compartilhado, em que o usu√°rio do sistema pode executar, concorrentemente, v√°rios programas, tendo a ilus√£o de que est√£o todos executando em paralelo.

Vimos ainda como a implementa√ß√£o de subprocessos e threads podem ser utilizados para o desenvolvimento de aplica√ß√µes que fa√ßam uso da capacidade de multiprocessamento dos sistemas atuais. Tal t√©cnica √© de suma import√¢ncia para o desenvolvimento de sistemas de alto desempenho.

Na parte de comunica√ß√£o e sincroniza√ß√£o entre processos, voc√™ pode perceber que, apesar do desempenho que pode ser obtido com a programa√ß√£o concorrente, cuidados devem ser tomados, principalmente no tocante √† atualiza√ß√£o de dados compartilhados. Para isso, podemos utilizar t√©cnicas oferecidas pelo sistema operacional, como sem√°foros, que definem e controlam o acesso a regi√µes cr√≠ticas, evitando as condi√ß√µes de corrida.

Por fim, estudamos os principais algoritmos de escalonamento que podem ser implementados pelos sistemas operacionais, vendo as principais carater√≠sticas de cada um deles. Como exemplo de algoritmos de escalonamento, vimos tamb√©m como o Linux faz para selecionar o pr√≥ximo processo a ser colocado em execu√ß√£o.

Conclu√≠mos que o conhecimento acerca da ger√™ncia do processador de um sistema operacional e de como se comportam processos, subprocessos e threads eleva o n√≠vel de conhecimento de um desenvolvedor/programador, permitindo que ele se torne apto ao desenvolvimento de sistemas melhores e de maior desempenho.


-------------




